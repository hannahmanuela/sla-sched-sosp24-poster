%-------------------------------------------------------------------------------
\section{Introduction}
%-------------------------------------------------------------------------------

Developers use Service Level Objectives (SLOs) between teams and Service Level
Agreements (SLAs) towards customers, each of which represent guarantees about
uptime and maximal latencies of the API that team/company is in charge
of~\cite{awssla}. Monitoring systems watch performance and page on-call
developers if these guarantees are not being met~\cite{cloudwatch}.

Cloud-compute providers, on the other hand, have as their central metric of
success/value utilization. The more work they can efficiently bin-pack onto
their machines, the more money they make. The interface cloud providers offer in
order to acheive this is well-known: latency-critical (LC) applications have
concrete reservations, and jobs with no immediate deadline can be run as cheaper
best-effort (BE) tasks. Cloud providers then bin-pack LC work, as well as
schedule in BE work opportunistically. This is not a simple proposition, but
researchers have built systems that do well at keeping utilization high, given
enough best-effort work~\cite{caladan}.


For a developer to translate their requirements into the cloud providers'
interface requires two steps: pick a category (LC or BE), and if the its the
former, generate a concrete reservation. Both of these steps are lossy: some
work might not be completely LC or BE, and reservations require the developer to
make estimations about peak load, and in fact incentivizes them to
overestimate~\cite*{overprovision} --- directly in opposition of the cloud
providers goals.

Imagine a web developer, whose website has four different types of work it has
to do: \\
(1) load static pages (eg the homepage) --- shortest and very time critical \\
(2) load dynamic pages (eg a users profile page) --- slightly longer and less
time critcial \\
(3) foreground data processing (eg processing a user uploaded file of image) ---
require a fair amount of processing but is still user-facing and thus latency
sensitive \\
(4) background data processing (eg updating a data warehouse) --- run overnight
and just needs to finish by morning.

The only candidate for best effort work is (4) (even that needs to be done by
the time business picks up the next day). The other three are user-facing and as
such require latency-critical and require reservations. How much these
reservations are over-provisioned will reflect the developers interest in
keeping low latency: it is critical that the homepage load time be constant,
whereas processing a user upload might be fine to take more time at high load.

Central to \textit{\sysname{}} is the observation that the original priorities
of utilization and latency don't have to be opposing. Rather than fighting the
symptom of underutilization caused by overprovisioning, \sysname{} changes the
interface.\ \sysname{} makes deadlines and maximum compute times the central
scheduling mechanism, thereby side-stepping the LC/BE binary and making the
developers requirements explicit to the scheduler. The cloud provider can use
the information of how long a process will run to make better placement
decisions.

%-------------------------------------------------------------------------------
\section{Design}
%-------------------------------------------------------------------------------

\begin{figure}[t!]
    \centering
    \includegraphics[height=1.5in]{img/eevdf.png}
    \caption{An example EEVDF timeline. Arrows represent requests, denoted with time eligible and deadline, 
        and boxes showing which process is chosen to run. }
    \label{eevdf}
\end{figure}

\begin{figure*}[h!]
    \centering
    \begin{subfigure}[t]{0.5\textwidth}
        \centering
        \includegraphics[height=2in]{img/old_lnx__2ms_wait__10K_iter.png}
        \caption{Latency and utilization in original linux}
    \end{subfigure}%
    \hfill
    \begin{subfigure}[t]{0.5\textwidth}
        \centering
        \includegraphics[height=2in]{img/new_lnx__2ms_wait__10K_iter.png}
        \caption{Latency and utilization in modified linux}
        \label{fig:graph:new}
    \end{subfigure}
    \vspace{10pt}
    \caption{Results of running the same workload on (a) unmodified and (b) modified linux.}
    \label{fig:graph}
\end{figure*}

Developers submit jobs, attached with the maximum execution time as well as a
deadline. 

When a job is run, it is initially routed to the relevant shard of the
\textit{global scheduler} \ref{DGS}, which then forwards the job to a chosen
single machine \ref{SM}. 


\subsection*{Distributed Global Scheduler}
\label{DGS}

Each global scheduler shard has a set of machines that it can run jobs on. The
goal of the global scheduler is to keep load as evenly distributed among these
machines as possible, in the sense that each machine has a maximally
heterogenous set of deadlines and computes. This allows processes with more
\textit{slack} (difference between deadline and max compute) to fill in gaps
where shorter processes might have finished earlier than expected (similarly to
how best effort work now opportunistically uses resources not currently used by
latency critical tasks).

Depending on the amount of slack the global scheduler will either immediately
place the job, or will probe a dynamic number of machines in order to find a
good match.


\subsection*{Single machine}
\label{SM}

On the individual machines, the goal is to to meet all the deadlines of the work
assigned to the machine. This has two parts: one is a dispatcher thread, which
handles communication with its global scheduler shard and does admission
control; and the other is a local scheduler that prioritizes work by deadline.

Admission control is pessismistc, and assumes that every process will use the
maximum compute time. The dispatcher looks at the amount of slack each process
has (given the original slack and how much time it has already spent waiting),
and then judges whether a new process would still allow the machine to meet all
the maximum compute guarantees.


The local scheduler approximates Earliest Deadline First (EDF) scheduling.
\sysname{} acheives EDF scheduling by using EEVDF - originally proposed in the 90s
and recently integrated in linux - at one extreme.

% have a figure with two processes making requests and getting time?

In EEVDF, processes make requests for resources, and each request is assigned an
eligible time and a deadline. At every scheduling point, of the eligible
processes the one with the earliest deadline is chosen to run next. Eligible
times and deadlines are in virtual time, which allows for oversubscription. 

Processes need to be able to be ineligible in order to maintain fairness. If a
process ran for the last tick and completed its latest request, its next
eligible time will be set to be in the future (a weighted estimation of by when
it should have gotten the time it just did, based on its weight as well the the
total system load). This protects against starvation of processes with longer
deadlines.

If jobs make requests often and for small time increments, this policy is
similar to PS - each process runs for a scheduling quanta before becoming
ineligible. However, on the other extreme you get behavior closer to EDF - if
jobs only ever make one request for all the resources that they think they will
need, then the requests never reset and all processes are always elgibible,
leading the EDF choice to be among all processes.

And creating this edge condiiton is what the dispatcher does - when it spawns a
process for a new job, it sets the requested timeslice of that job to be the
jobs maximum compute. 

